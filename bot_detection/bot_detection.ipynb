{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.costum_keys import CustomKeys as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bot_detection_dataset.csv')\n",
    "df = df.drop(columns=[\n",
    "    ck.ADDRESS, \n",
    "    ck.ERC20_MOST_REC_TOKEN_TYPE, \n",
    "    ck.ERC20_MOST_SENT_TOKEN_TYPE,\n",
    "    ck.DATA_SOURCE,\n",
    "    ck.LABEL_SOURCE,\n",
    "    ]).astype(np.float64)\n",
    "df = df.dropna()\n",
    "negatives = df[df[ck.FLAG] == ck.NEGATIVE_FLAG]\n",
    "kaggle_labeled_bots = df[df[ck.FLAG] == ck.KAGGLE_LABELED_BOT_FLAG]\n",
    "mev_bots = df[df[ck.FLAG] == ck.MEV_BOT_FLAG]\n",
    "spams = df[df[ck.FLAG] == ck.SPAM_FLAG]\n",
    "positives = kaggle_labeled_bots.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = negatives.sample(frac=1)\n",
    "negatives, calibration = negatives.iloc[:-n], negatives.iloc[-n:]\n",
    "positives = positives.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_folds = np.array_split(positives.values, 4)\n",
    "negative_folds = np.array_split(negatives.values, 4)\n",
    "folds = []\n",
    "for i in range(4):\n",
    "    fold = np.concatenate([positive_folds[i], negative_folds[i]])\n",
    "    np.random.shuffle(fold)\n",
    "    folds.append(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.copy(folds[0])\n",
    "train_data = np.concatenate(folds[1:])\n",
    "train_x, train_y = train_data[:, 1:], train_data[:, 0]\n",
    "cal_x, cal_y = calibration.values[:, 1:], calibration.values[:, 0]\n",
    "test_x, test_y = test_data[:, 1:], test_data[:, 0]\n",
    "scaler = StandardScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "cal_x_scaled = scaler.transform(cal_x)\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "n_features = train_x.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6008, 45), (1000, 45), (2004, 45))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_scaled.shape, cal_x_scaled.shape, test_x_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "Dense = tf.keras.layers.Dense\n",
    "model.add(Dense(64, input_shape=(n_features,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(train_y),\n",
    "    y = train_y.flatten(),\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 1s 1ms/step - loss: 0.6110 - accuracy: 0.6548\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7578\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.7994\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8296\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8660\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2760 - accuracy: 0.8888\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9171\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.9274\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9343\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9369\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9412\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9436\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.9477\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9479\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9494\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9521\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9522\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9524\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9557\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9542\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9547\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9577\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9564\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9581\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9591\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9587\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9606\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9592\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9597\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2fb6dd160>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_x_scaled,\n",
    "    train_y, \n",
    "    epochs=30, \n",
    "    batch_size=32, \n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_x_scaled)\n",
    "cal_predictions = model.predict(cal_x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_negative = predictions[np.where(test_y == 0)[0]]\n",
    "preds_positive = predictions[np.where(test_y == 1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03, 1000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem setup\n",
    "alpha = 0.03 # 1-alpha is the desired type-1 error\n",
    "alpha, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the outlier detection method to get a threshold on the toxicities\n",
    "qhat = np.quantile(cal_predictions, np.ceil((n+1)*(1-alpha))/n)\n",
    "# Perform outlier detection on the ind and ood data\n",
    "outlier_ind = preds_negative > qhat # We want this to be no more than alpha on average\n",
    "outlier_ood = preds_positive > qhat # We want this to be as large as possible, but it doesn't have a guarantee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type-1 error is 0.0240, the type-2 error is 0.1065, and the threshold is 0.6615.\n"
     ]
    }
   ],
   "source": [
    "# Calculate type-1 and type-2 errors\n",
    "type1 = outlier_ind.mean()\n",
    "type2 = 1-outlier_ood.mean()\n",
    "print(f\"The type-1 error is {type1:.4f}, the type-2 error is {type2:.4f}, and the threshold is {qhat:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calculate_mcc(tp, tn, fp, fn):\n",
    "    numerator = tp * tn - fp * fn\n",
    "    denominator = sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    mcc = numerator / denominator if denominator else 0\n",
    "    return mcc\n",
    "\n",
    "def __calculate_cohen_kappa(tn, fp, fn, tp):\n",
    "    total = tp + fp + fn + tn\n",
    "    p0 = (tp + tn) / total\n",
    "    pe = ((tp + fp) * (tp + fn) + (tn + fp) * (tn + fn)) / (total * total)\n",
    "    kappa = (p0 - pe) / (1 - pe)\n",
    "    return kappa\n",
    "\n",
    "def __calculate_scores(metrics):\n",
    "    _, tn, fp, fn, tp, _, _ = metrics\n",
    "    balanced_accuracy = (tp / (tp + fn) + tn / (tn + fp)) / 2\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    mcc = __calculate_mcc(tp, tn, fp, fn)\n",
    "    cohen_kappa = __calculate_cohen_kappa(tn, fp, fn, tp)\n",
    "    g_mean = sqrt((tp / (tp + fn)) * (tn / (tn + fp)))\n",
    "    return balanced_accuracy, precision, recall, f1_score, mcc, \\\n",
    "        cohen_kappa, g_mean\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    accuracy, tn, fp, fn, tp, auc_pr, auc_roc = metrics\n",
    "    balanced_accuracy, precision, recall, f1_score, mcc, \\\n",
    "        cohen_kappa, g_mean =  __calculate_scores(metrics)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.2f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.2f}\")\n",
    "    print(f\"MCC: {mcc:.2f}\")\n",
    "    print(f\"Cohen's Kappa: {cohen_kappa:.2f}\")\n",
    "    print(f\"G-Mean: {g_mean:.2f}\")\n",
    "    print(f\"True negatives: {tn}\")\n",
    "    print(f\"False positives: {fp}\")\n",
    "    print(f\"False negatives: {fn}\")\n",
    "    print(f\"True positives: {tp}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformal Prediction\n",
      "Accuracy: 0.96\n",
      "Balanced Accuracy: 0.93\n",
      "Precision: 0.88\n",
      "Recall: 0.89\n",
      "F1 Score: 0.89\n",
      "AUC-ROC: 0.93\n",
      "AUC-PR: 0.93\n",
      "MCC: 0.87\n",
      "Cohen's Kappa: 0.87\n",
      "G-Mean: 0.93\n",
      "True negatives: 1626\n",
      "False positives: 40\n",
      "False negatives: 36\n",
      "True positives: 302\n"
     ]
    }
   ],
   "source": [
    "predictions_binary = [1 if p > qhat else 0 for p in predictions]\n",
    "\n",
    "# Print the accuracy of the model\n",
    "accuracy = accuracy_score(test_y, predictions_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, predictions_binary).ravel()\n",
    "fpr, tpr, _ = roc_curve(test_y, predictions_binary)\n",
    "auc_pr = auc(fpr, tpr)\n",
    "auc_roc = roc_auc_score(test_y, predictions_binary)\n",
    "m = accuracy, tn, fp, fn, tp, auc_pr, auc_roc\n",
    "print('Conformal Prediction')\n",
    "print_metrics(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Prediction\n",
      "Accuracy: 0.96\n",
      "Balanced Accuracy: 0.95\n",
      "Precision: 0.85\n",
      "Recall: 0.93\n",
      "F1 Score: 0.89\n",
      "AUC-ROC: 0.95\n",
      "AUC-PR: 0.95\n",
      "MCC: 0.87\n",
      "Cohen's Kappa: 0.86\n",
      "G-Mean: 0.95\n",
      "True negatives: 1612\n",
      "False positives: 54\n",
      "False negatives: 25\n",
      "True positives: 313\n"
     ]
    }
   ],
   "source": [
    "predictions_binary = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Print the accuracy of the model\n",
    "accuracy = accuracy_score(test_y, predictions_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(test_y, predictions_binary).ravel()\n",
    "fpr, tpr, _ = roc_curve(test_y, predictions_binary)\n",
    "auc_pr = auc(fpr, tpr)\n",
    "auc_roc = roc_auc_score(test_y, predictions_binary)\n",
    "m = accuracy, tn, fp, fn, tp, auc_pr, auc_roc\n",
    "print('Binary Prediction')\n",
    "print_metrics(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
